{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131c7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ares/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.logging import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import cloudpickle\n",
    "import sys\n",
    "\n",
    "from typing import Iterable, List\n",
    "#from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score,homogeneity_score,completeness_score,v_measure_score,silhouette_score\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import get_scorer,silhouette_score\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a378c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# CLUSTER\n",
    "CLUSTER_MIN = 2\n",
    "CLUSTER_MAX = 15\n",
    "CLUSTER_STEP = 1\n",
    "\n",
    "LOG_ONLY_BEST=True\n",
    "\n",
    "# data\n",
    "DATA_PATH = './data/yelp_labelled.txt'\n",
    "\n",
    "# sentence transformer\n",
    "# choose one from https://www.sbert.net/docs/pretrained_models.html\n",
    "MODEL_NAME = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "\n",
    "# Eval Metrics\n",
    "EVAL_METRICS = ['silhouette_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file {DATA_PATH}...\n",
      "Load complete: 1000 rows and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "logger.info('Loading file {DATA_PATH}...')\n",
    "df = pd.read_csv(DATA_PATH, header=None,\n",
    "                 sep='\\t', names=['sentence', 'label'])\n",
    "logger.info(f'Load complete: {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25b04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sentence transformer multi-qa-MiniLM-L6-cos-v1...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sentcluster import BertEmbedder\n",
    "logger.info(f'Loading sentence transformer {MODEL_NAME}...')\n",
    "embedder = BertEmbedder(MODEL_NAME)\n",
    "logger.info(f'done.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53aa7e19",
   "metadata": {},
   "source": [
    "# Config conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d03ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import version_info\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(\n",
    "    major=version_info.major, minor=version_info.minor, micro=version_info.micro\n",
    ")\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\"],\n",
    "    \"dependencies\": [\"python={}\".format(PYTHON_VERSION), \"pip\"],\n",
    "    \"pip\": [\n",
    "        \"mlflow\",\n",
    "        \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "        \"vaderSentiment==3.3.2\",\n",
    "    ],\n",
    "    \"name\": \"mlflow-env\",\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2a8f706",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be44afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 67.39it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.66it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 78.32it/s]\n",
      "n_cluster=2, silhouette_score=0.06888\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.14it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.30it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.88it/s]\n",
      "n_cluster=3, silhouette_score=0.05623\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.00it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.18it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.61it/s]\n",
      "n_cluster=4, silhouette_score=0.04648\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.93it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 77.84it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 79.23it/s]\n",
      "n_cluster=5, silhouette_score=0.04916\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.77it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.68it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.35it/s]\n",
      "n_cluster=6, silhouette_score=0.04911\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.10it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.23it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.23it/s]\n",
      "n_cluster=7, silhouette_score=0.04741\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 68.76it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.06it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.20it/s]\n",
      "n_cluster=8, silhouette_score=0.04531\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.12it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 66.05it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.36it/s]\n",
      "n_cluster=9, silhouette_score=0.04295\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.70it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.79it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 68.55it/s]\n",
      "n_cluster=10, silhouette_score=0.03851\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.52it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.67it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.28it/s]\n",
      "n_cluster=11, silhouette_score=0.03836\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.12it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.03it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.52it/s]\n",
      "n_cluster=12, silhouette_score=0.03870\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.61it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.53it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 77.61it/s]\n",
      "n_cluster=13, silhouette_score=0.03637\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.42it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.41it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.42it/s]\n",
      "n_cluster=14, silhouette_score=0.04276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "pipe = Pipeline([('embedder',embedder),('clusterer',KMeans())])\n",
    "\n",
    "best_metric = np.Inf\n",
    "best_labels = None\n",
    "\n",
    "for current_n in range(CLUSTER_MIN, CLUSTER_MAX, CLUSTER_STEP):\n",
    "    with mlflow.start_run():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        mlflow.log_param(\"n_clusters\", current_n)\n",
    "        model_start_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        pipe.set_params(**{'clusterer__n_clusters':current_n})\n",
    "        predicted_2d = pipe.fit(df.sentence)\n",
    "        predicted_labels = pipe.predict(df.sentence)\n",
    "\n",
    "        current_metric = silhouette_score(pipe['embedder'].transform(df.sentence),predicted_labels)\n",
    "        \n",
    "        # Print out Silhouette Score and log it in mlflow\n",
    "        logger.info(f\"n_cluster={current_n}, silhouette_score={current_metric:.5f}\")\n",
    "\n",
    "        if LOG_ONLY_BEST:\n",
    "            if current_metric < best_metric:\n",
    "                best_metric = current_metric \n",
    "                mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "                mlflow.log_metric('silhouette_score', best_metric)\n",
    "                mlflow.sklearn.save_model(pipe,f'models/{model_start_time}_{MODEL_NAME}_KMeans_(n={current_n}',conda_env=conda_env)\n",
    "                best_labels = predicted_labels\n",
    "        else:\n",
    "                mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "                mlflow.log_metric('silhouette_score', current_metric)\n",
    "                mlflow.sklearn.save_model(pipe,f'models/{model_start_time}_{MODEL_NAME}_KMeans_(n={current_n}',conda_env=conda_env)\n",
    "                best_labels = predicted_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61243a0f",
   "metadata": {},
   "source": [
    "# Generate scored dataset with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb7d74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame( {'sentence':df.sentence,'label':best_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080126a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "samples from cluster=10\n",
      "['Wow... Loved this place.'\n",
      " 'This place is not worth your time, let alone Vegas.'\n",
      " 'I could care less... The interior is just beautiful.'\n",
      " 'I found this place by accident and I could not be happier.'\n",
      " 'Overall, I like this place a lot.'\n",
      " 'This place receives stars for their APPETIZERS!!!'\n",
      " 'We are so glad we found this place.'\n",
      " \"I guess I should have known that this place would suck, because it is inside of the Excalibur, but I didn't use my common sense.\"\n",
      " 'This place has it!'\n",
      " 'Although I very much liked the look and sound of this place, the actual experience was a bit disappointing.']\n",
      "\n",
      "\n",
      "samples from cluster=1\n",
      "['Crust is not good.' 'The food, amazing.'\n",
      " 'Also there are combos like a burger, fries, and beer for 23 which is a decent deal.'\n",
      " 'Ample portions and good prices.'\n",
      " 'The only thing I did like was the prime rib and dessert section.'\n",
      " \"It's too bad the food is so damn generic.\"\n",
      " 'Great food and service, huge portions and they give a military discount.'\n",
      " 'The scallop dish is quite appalling for value as well.'\n",
      " 'Phenomenal food, service and ambiance.'\n",
      " 'This place is way too overpriced for mediocre food.']\n",
      "\n",
      "\n",
      "samples from cluster=12\n",
      "['Not tasty and the texture was just nasty.'\n",
      " \"Honeslty it didn't taste THAT fresh.)\"\n",
      " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.'\n",
      " \"That's right....the red velvet cake.....ohhh this stuff is so good.\"\n",
      " 'The shrimp tender and moist.'\n",
      " \"Hard to judge whether these sides were good because we were grossed out by the melted styrofoam and didn't want to eat it for fear of getting sick.\"\n",
      " 'My side Greek salad with the Greek dressing was so tasty, and the pita and hummus was very refreshing.'\n",
      " 'We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.'\n",
      " 'The ripped banana was not only ripped, but petrified and tasteless.'\n",
      " 'We got the food and apparently they have never heard of salt and the batter on the fish was chewy.']\n",
      "\n",
      "\n",
      "samples from cluster=2\n",
      "['Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.'\n",
      " 'I was disgusted because I was pretty sure that was human hair.'\n",
      " 'I was shocked because no signs indicate cash only.'\n",
      " 'did not like at all.' 'So they performed.'\n",
      " 'This was like the final blow!'\n",
      " 'Frozen pucks of disgust, with some of the worst people behind the register.'\n",
      " 'The portion was huge!'\n",
      " 'Update.....went back for a second time and it was still just as amazing'\n",
      " 'It was not good.']\n",
      "\n",
      "\n",
      "samples from cluster=0\n",
      "['The selection on the menu was great and so were the prices.'\n",
      " 'The Burrittos Blah!' 'My first visit to Hiro was a delight!'\n",
      " 'Their chow mein is so good!'\n",
      " 'The cocktails are all handmade and delicious.'\n",
      " 'Always a great time at Dos Gringos!'\n",
      " 'I love the Pho and the spring rolls oh so yummy you have to try.'\n",
      " 'Omelets are to die for!'\n",
      " 'The ambience is wonderful and there is music playing.'\n",
      " \"REAL sushi lovers, let's be honest - Yama is not that good.\"]\n",
      "\n",
      "\n",
      "samples from cluster=4\n",
      "['Now I am getting angry and I want my damn pho.' 'A great touch.'\n",
      " 'Highly recommended.'\n",
      " 'There is not a deal good enough that would drag me into that establishment again.'\n",
      " 'A great way to finish a great.' 'Sooooo good!!' 'Good prices.'\n",
      " 'Check it out.' \"Don't do it!!!!\" 'I give it 2 thumbs down']\n",
      "\n",
      "\n",
      "samples from cluster=11\n",
      "['The fries were great too.' 'The worst was the salmon sashimi.'\n",
      " 'Loved it...friendly servers, great food, wonderful and imaginative menu.'\n",
      " 'All I have to say is the food was amazing!!!'\n",
      " 'Everything was fresh and delicious!'\n",
      " \"The only good thing was our waiter, he was very helpful and kept the bloddy mary's coming.\"\n",
      " 'The food was delicious, our bartender was attentive and personable AND we got a great deal!'\n",
      " 'Service was fine and the waitress was friendly.'\n",
      " 'The service was a little slow , considering that were served by 3 people servers so the food was coming in a slow pace.'\n",
      " 'The food sucked, which we expected but it sucked more than we could have imagined.']\n",
      "\n",
      "\n",
      "samples from cluster=5\n",
      "['Service was very prompt.' 'Service is also cute.' 'Service sucks.'\n",
      " 'On a positive note, our server was very attentive and provided great service.'\n",
      " 'The service was meh.' '2 times - Very Bad Customer Service !'\n",
      " 'Worst service to boot, but that is the least of their worries.'\n",
      " 'The service here leaves a lot to be desired.'\n",
      " 'Service is friendly and inviting.' 'The service was a bit lacking.']\n",
      "\n",
      "\n",
      "samples from cluster=6\n",
      "['Would not go back.' \"We'd definitely go back here again.\"\n",
      " \"We'll never go again.\" 'Will be back again!'\n",
      " 'Will go back next trip out.' \"I wouldn't return.\" \"Won't go back.\"\n",
      " 'I think not again' 'Will never, ever go back.' 'Never going back.']\n",
      "\n",
      "\n",
      "samples from cluster=8\n",
      "['The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.'\n",
      " 'Waitress was a little slow in service.'\n",
      " 'Poor service, the waiter made me feel like I was stupid every time he came to the table.'\n",
      " 'He came running after us when he realized my husband had left his sunglasses on the table.'\n",
      " \"They have horrible attitudes towards customers, and talk down to each one when customers don't enjoy their food.\"\n",
      " \"Coming here is like experiencing an underwhelming relationship where both parties can't wait for the other person to ask to break up.\"\n",
      " \"It's like a really sexy party in your mouth, where you're outrageously flirting with the hottest person at the party.\"\n",
      " 'say bye bye to your tip lady!'\n",
      " 'Host staff were, for lack of a better word, BITCHES!'\n",
      " 'The management is rude.']\n",
      "\n",
      "\n",
      "samples from cluster=9\n",
      "['I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!'\n",
      " 'The burger is good beef, cooked just right.'\n",
      " 'Not much seafood and like 5 strings of pasta at the bottom.'\n",
      " 'The salad had just the right amount of sauce to not over power the scallop, which was perfectly cooked.'\n",
      " 'The turkey and roast beef were bland.'\n",
      " 'The poor batter to meat ratio made the chicken tenders very unsatisfying.'\n",
      " 'Our server was fantastic and when he found out the wife loves roasted garlic and bone marrow, he added extra to our meal and another marrow to go!'\n",
      " 'I LOVED their mussels cooked in this wine reduction, the duck was tender, and their potato dishes were delicious.'\n",
      " 'Kind of hard to mess up a steak but they did.'\n",
      " \"The guys all had steaks, and our steak loving son who has had steak at the best and worst places said it was the best steak he's ever eaten.\"]\n",
      "\n",
      "\n",
      "samples from cluster=7\n",
      "['- They never brought a salad we asked for.'\n",
      " 'Took an hour to get our food only 4 tables in restaurant my food was Luke warm, Our sever was running around like he was totally overwhelmed.'\n",
      " 'At least think to refill my water before I struggle to wave you over for 10 minutes.'\n",
      " 'It took over 30 min to get their milkshake, which was nothing more than chocolate milk.'\n",
      " 'walked in and the place smelled like an old grease trap and only 2 others there eating.'\n",
      " 'Food arrived quickly!'\n",
      " \"At least 40min passed in between us ordering and the food arriving, and it wasn't that busy.\"\n",
      " 'I had a seriously solid breakfast here.'\n",
      " 'My husband and I ate lunch here and were very disappointed with the food and service.'\n",
      " 'My fiancé and I came in the middle of the day and we were greeted and seated right away.']\n",
      "\n",
      "\n",
      "samples from cluster=3\n",
      "['This hole in the wall has great Mexican street tacos, and friendly staff.'\n",
      " 'seems like a good quick place to grab a bite of some familiar pub food, but do yourself a favor and look elsewhere.'\n",
      " 'The only redeeming quality of the restaurant was that it was very inexpensive.'\n",
      " 'If you want a sandwich just go to any Firehouse!!!!!'\n",
      " 'The Heart Attack Grill in downtown Vegas is an absolutely flat-lined excuse for a restaurant.'\n",
      " \"Today is the second time I've been to their lunch buffet and it was pretty good.\"\n",
      " 'There is so much good food in Vegas that I feel cheated for wasting an eating opportunity by going to Rice and Company.'\n",
      " 'In summary, this was a largely disappointing dining experience.'\n",
      " 'Never been to Hard Rock Casino before, WILL NEVER EVER STEP FORWARD IN IT AGAIN!'\n",
      " 'Best breakfast buffet!!!']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in results_df.label.unique():\n",
    "    logger.info(f'samples from cluster={r}')\n",
    "    logger.info(results_df[results_df.label==r].head(10).sentence.values)\n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac734acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/79ab3cd9f79547d48fa11a9475805744/multi-qa-MiniLM-L6-cos-v1_KMeans_(n=13)'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_1",
   "language": "python",
   "name": "kaggle_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
