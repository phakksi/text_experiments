{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "131c7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logging import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "import cloudpickle\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a378c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# CLUSTER\n",
    "CLUSTER_MIN = 5\n",
    "CLUSTER_MAX = 15\n",
    "CLUSTER_STEP = 1\n",
    "\n",
    "LOG_ONLY_BEST=True\n",
    "\n",
    "# data\n",
    "DATA_PATH = './data/yelp_labelled.txt'\n",
    "\n",
    "# sentence transformer\n",
    "# choose one from https://www.sbert.net/docs/pretrained_models.html\n",
    "MODEL_NAME = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "\n",
    "# Eval Metrics\n",
    "EVAL_METRICS = ['silhouette_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b1883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file {DATA_PATH}...\n",
      "Load complete: 1000 rows and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "logger.info('Loading file {DATA_PATH}...')\n",
    "df = pd.read_csv(DATA_PATH, header=None,\n",
    "                 sep='\\t', names=['sentence', 'label'])\n",
    "logger.info(f'Load complete: {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f25b04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sentence transformer multi-qa-MiniLM-L6-cos-v1...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sentcluster import BertEmbedder\n",
    "logger.info(f'Loading sentence transformer {MODEL_NAME}...')\n",
    "embedder = BertEmbedder(MODEL_NAME)\n",
    "logger.info(f'done.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53aa7e19",
   "metadata": {},
   "source": [
    "# Config conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d03ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import version_info\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(\n",
    "    major=version_info.major, minor=version_info.minor, micro=version_info.micro\n",
    ")\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\"],\n",
    "    \"dependencies\": [\"python={}\".format(PYTHON_VERSION), \"pip\"],\n",
    "    \"pip\": [\n",
    "        \"mlflow\",\n",
    "        \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "        \"scikit-learn==1.2.2\",\n",
    "        \"sentence-transformers==2.2.2\"\n",
    "    ],\n",
    "    \"name\": \"mlflow-env\",\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2a8f706",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be44afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.06it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.80it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 68.22it/s]\n",
      "n_cluster=5, silhouette_score=0.04953\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.66it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.79it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 78.26it/s]\n",
      "n_cluster=6, silhouette_score=0.04882\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.41it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.40it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.29it/s]\n",
      "n_cluster=7, silhouette_score=0.04781\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 78.36it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.03it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.27it/s]\n",
      "n_cluster=8, silhouette_score=0.04357\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.74it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.97it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 77.88it/s]\n",
      "n_cluster=9, silhouette_score=0.04590\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.35it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.20it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 79.16it/s]\n",
      "n_cluster=10, silhouette_score=0.03851\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.03it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.51it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.04it/s]\n",
      "n_cluster=11, silhouette_score=0.04332\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 68.53it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.46it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.13it/s]\n",
      "n_cluster=12, silhouette_score=0.04030\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.56it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.42it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.30it/s]\n",
      "n_cluster=13, silhouette_score=0.04209\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.02it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.48it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 79.41it/s]\n",
      "n_cluster=14, silhouette_score=0.04698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "pipe = Pipeline([('embedder',embedder),('clusterer',KMeans())])\n",
    "\n",
    "best_metric = np.Inf\n",
    "best_labels = None\n",
    "\n",
    "for current_n in range(CLUSTER_MIN, CLUSTER_MAX, CLUSTER_STEP):\n",
    "    with mlflow.start_run():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        mlflow.log_param(\"n_clusters\", current_n)\n",
    "        model_start_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        pipe.set_params(**{'clusterer__n_clusters':current_n})\n",
    "        predicted_2d = pipe.fit(df.sentence)\n",
    "        predicted_labels = pipe.predict(df.sentence)\n",
    "\n",
    "        current_metric = silhouette_score(pipe['embedder'].transform(df.sentence),predicted_labels)\n",
    "        \n",
    "        logger.info(f\"n_cluster={current_n}, silhouette_score={current_metric:.5f}\")\n",
    "\n",
    "        if LOG_ONLY_BEST and current_metric < best_metric:\n",
    "            best_metric = current_metric \n",
    "            mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "            mlflow.log_metric('silhouette_score', best_metric)\n",
    "            best_labels = predicted_labels\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "            mlflow.log_metric('silhouette_score', current_metric)\n",
    "            best_labels = predicted_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61243a0f",
   "metadata": {},
   "source": [
    "# Generate scored dataset with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb7d74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame( {'sentence':df.sentence,'label':best_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "080126a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "samples from cluster=0\n",
      "------------------------------------\n",
      "Would not go back.\n",
      "We'd definitely go back here again.\n",
      "We'll never go again.\n",
      "Will be back again!\n",
      "Will go back next trip out.\n",
      "------------------------------------\n",
      "samples from cluster=1\n",
      "------------------------------------\n",
      "Wow... Loved this place.\n",
      "This place is not worth your time, let alone Vegas.\n",
      "I found this place by accident and I could not be happier.\n",
      "Overall, I like this place a lot.\n",
      "My first visit to Hiro was a delight!\n",
      "------------------------------------\n",
      "samples from cluster=2\n",
      "------------------------------------\n",
      "The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.\n",
      "I was disgusted because I was pretty sure that was human hair.\n",
      "I was shocked because no signs indicate cash only.\n",
      "Waitress was a little slow in service.\n",
      "Poor service, the waiter made me feel like I was stupid every time he came to the table.\n",
      "------------------------------------\n",
      "samples from cluster=3\n",
      "------------------------------------\n",
      "Not tasty and the texture was just nasty.\n",
      "The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\n",
      "The Burrittos Blah!\n",
      "The food, amazing.\n",
      "That's right....the red velvet cake.....ohhh this stuff is so good.\n",
      "------------------------------------\n",
      "samples from cluster=4\n",
      "------------------------------------\n",
      "Also there are combos like a burger, fries, and beer for 23 which is a decent deal.\n",
      "seems like a good quick place to grab a bite of some familiar pub food, but do yourself a favor and look elsewhere.\n",
      "The only redeeming quality of the restaurant was that it was very inexpensive.\n",
      "The only thing I did like was the prime rib and dessert section.\n",
      "The burger is good beef, cooked just right.\n",
      "------------------------------------\n",
      "samples from cluster=5\n",
      "------------------------------------\n",
      "The fries were great too.\n",
      "The worst was the salmon sashimi.\n",
      "The portion was huge!\n",
      "The turkey and roast beef were bland.\n",
      "All I have to say is the food was amazing!!!\n",
      "------------------------------------\n",
      "samples from cluster=6\n",
      "------------------------------------\n",
      "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
      "The selection on the menu was great and so were the prices.\n",
      "Highly recommended.\n",
      "Ample portions and good prices.\n",
      "There is not a deal good enough that would drag me into that establishment again.\n",
      "------------------------------------\n",
      "samples from cluster=7\n",
      "------------------------------------\n",
      "Crust is not good.\n",
      "It's too bad the food is so damn generic.\n",
      "They have horrible attitudes towards customers, and talk down to each one when customers don't enjoy their food.\n",
      "Phenomenal food, service and ambiance.\n",
      "This place is way too overpriced for mediocre food.\n",
      "------------------------------------\n",
      "samples from cluster=8\n",
      "------------------------------------\n",
      "This hole in the wall has great Mexican street tacos, and friendly staff.\n",
      "REAL sushi lovers, let's be honest - Yama is not that good.\n",
      "We thought you'd have to venture further away to get good sushi, but this place really hit the spot that night.\n",
      "Nice blanket of moz over top but i feel like this was done to cover up the subpar food.\n",
      "Much better than the other AYCE sushi place I went to in Vegas.\n",
      "------------------------------------\n",
      "samples from cluster=9\n",
      "------------------------------------\n",
      "Now I am getting angry and I want my damn pho.\n",
      "A great touch.\n",
      "did not like at all.\n",
      "So they performed.\n",
      "This was like the final blow!\n",
      "------------------------------------\n",
      "samples from cluster=10\n",
      "------------------------------------\n",
      "I could care less... The interior is just beautiful.\n",
      "The ambience is wonderful and there is music playing.\n",
      "Bland... Not a liking this place for a number of reasons and I don't want to waste time on bad reviewing.. I'll leave it at that...\n",
      "The bathrooms are clean and the place itself is well decorated.\n",
      "the staff is friendly and the joint is always clean.\n",
      "------------------------------------\n",
      "samples from cluster=11\n",
      "------------------------------------\n",
      "Honeslty it didn't taste THAT fresh.)\n",
      "I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!\n",
      "- They never brought a salad we asked for.\n",
      "The shrimp tender and moist.\n",
      "Hard to judge whether these sides were good because we were grossed out by the melted styrofoam and didn't want to eat it for fear of getting sick.\n",
      "------------------------------------\n",
      "samples from cluster=12\n",
      "------------------------------------\n",
      "Took an hour to get our food only 4 tables in restaurant my food was Luke warm, Our sever was running around like he was totally overwhelmed.\n",
      "At least think to refill my water before I struggle to wave you over for 10 minutes.\n",
      "It took over 30 min to get their milkshake, which was nothing more than chocolate milk.\n",
      "Coming here is like experiencing an underwhelming relationship where both parties can't wait for the other person to ask to break up.\n",
      "Food arrived quickly!\n",
      "------------------------------------\n",
      "samples from cluster=13\n",
      "------------------------------------\n",
      "Service was very prompt.\n",
      "Service is also cute.\n",
      "Service sucks.\n",
      "On a positive note, our server was very attentive and provided great service.\n",
      "The service was meh.\n"
     ]
    }
   ],
   "source": [
    "for r in sorted(results_df.label.unique()):\n",
    "    logger.info(f'------------------------------------')\n",
    "    logger.info(f'samples from cluster={r}')\n",
    "    logger.info(f'------------------------------------')\n",
    "    for index,row in results_df[results_df.label==r].head(5).iterrows():\n",
    "        logger.info(row['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_1",
   "language": "python",
   "name": "kaggle_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
