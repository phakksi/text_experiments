{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment in databricks\n",
    "# %pip install mlflow\n",
    "# %pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow, pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('emilyalsentzer/Bio_ClinicalBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed6ca8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['not feeling very well, feeling lost',\n",
    "    'feeling healthy, stopped because of remission', \n",
    "    'stopped because of dry eyes and shortness of breath',\n",
    "    'feeling better, improving today, not feeling pain anymore',\n",
    "    'reports anxiety, anxious, cannot understand',\n",
    "     ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=2)\n",
    "predicted_2d = km.fit_transform(embeddings)\n",
    "predicted_labels = km.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be44afaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00620198, 0.00384712, 0.00360036, 0.00361276, 0.00530028]),\n",
       " 'score_time': array([0.00025964, 0.00015521, 0.00014758, 0.00014043, 0.00020623]),\n",
       " 'estimator': [KMeans(n_clusters=2),\n",
       "  KMeans(n_clusters=2),\n",
       "  KMeans(n_clusters=2),\n",
       "  KMeans(n_clusters=2),\n",
       "  KMeans(n_clusters=2)],\n",
       " 'test_score': array([-27.16184807, -27.28355408, -34.28046036, -28.56356239,\n",
       "        -40.49306488])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=2)\n",
    "cval = cross_validate(km,embeddings,cv=5,return_estimator=True)\n",
    "cval\n",
    "#predicted_2d = km.fit_transform(embeddings)\n",
    "#predicted_labels = km.predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43942e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "#from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score,homogeneity_score,completeness_score,v_measure_score,silhouette_score\n",
    "from collections import namedtuple\n",
    "import importlib \n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import get_scorer,silhouette_score\n",
    "\n",
    "import warnings\n",
    "CLUSTER_EVAL_METRICS_LIST = ['adjusted_rand_score',\n",
    "                     'adjusted_mutual_info_score',\n",
    "                     'normalized_mutual_info_score',\n",
    "                     'homogeneity_score','completeness_score',\n",
    "                     'v_measure_score']\n",
    "\n",
    "class SentenceKmeans():\n",
    "\n",
    "    def __init__(self, \n",
    "                 sentences:Iterable[str],\n",
    "                 true_labels:Iterable[str]=None,\n",
    "                 cluster_min: int=1,\n",
    "                 cluster_max: int=3,\n",
    "                 cluster_step: int=1,\n",
    "                 sentence_transformer_name: str='emilyalsentzer/Bio_ClinicalBERT',\n",
    "                 supervised_eval_metrics_list: List=['homogeneity_score','completeness_score'],\n",
    "                 random_seed: int = 42\n",
    "                ):\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.cluster_min = cluster_min\n",
    "        self.cluster_max = cluster_max\n",
    "        self.cluster_step = cluster_step\n",
    "        self.sentence_transformer = SentenceTransformer(sentence_transformer_name)\n",
    "        self.embedded_sentences = self.sentence_transformer.encode(self.sentences)\n",
    "        self.random_seed = 42\n",
    "        \n",
    "        if true_labels is None:\n",
    "            self.true_labels = np.zeros(len(self.sentences))\n",
    "        self.eval_metrics_list=supervised_eval_metrics_list\n",
    "\n",
    "    # Evaluate metrics\n",
    "    def eval_metrics(self,actual, pred):\n",
    "    \n",
    "        results = defaultdict(None)\n",
    "        \n",
    "        for met in self.eval_metrics_list:\n",
    "            if met == 'silhouette_score':\n",
    "                results['silhouette_score']=silhouette_score(self.embedded_sentences,pred)\n",
    "            else:\n",
    "                results[met] = get_scorer(met)._score_func(actual,pred)\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def train(self):\n",
    "        # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "        with mlflow.start_run():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            np.random.seed(self.random_seed)\n",
    "            for current_n in range(self.cluster_min, self.cluster_max, self.cluster_step):\n",
    "                mlflow.log_param(\"n_clusters\", current_n)\n",
    "                \n",
    "                km = KMeans(n_clusters=current_n)\n",
    "\n",
    "                predicted_labels = km.fit_predict(self.embedded_sentences)\n",
    "                predicted_2d = km.transform(self.embedded_sentences)\n",
    "                \n",
    "                metrics_dict = self.eval_metrics(self.true_labels,predicted_labels)\n",
    "\n",
    "                # Print out ElasticNet model metrics\n",
    "\n",
    "                print(f\"n_cluster={current_n}\")\n",
    "                for met in self.eval_metrics_list:\n",
    "                    print(f'{met} = {metrics_dict[met]:.4f} \\n')\n",
    "                    mlflow.log_metric(met, metrics_dict[met])\n",
    "                \n",
    "                \n",
    "                mlflow.sklearn.log_model(km, f\"KMeans (n={current_n})\")\n",
    "               # mlflow.sklearn.save_model(km,'./my_models')\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf8c1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceKmeans():\n",
    "\n",
    "    def __init__(self, \n",
    "                 sentences:Iterable[str],\n",
    "                 true_labels:Iterable[str]=None,\n",
    "                 cluster_min: int=1,\n",
    "                 cluster_max: int=3,\n",
    "                 cluster_step: int=1,\n",
    "                 sentence_transformer_name: str='emilyalsentzer/Bio_ClinicalBERT',\n",
    "                 supervised_eval_metrics_list: List=['homogeneity_score','completeness_score'],\n",
    "                 random_seed: int = 42\n",
    "                ):\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.cluster_min = cluster_min\n",
    "        self.cluster_max = cluster_max\n",
    "        self.cluster_step = cluster_step\n",
    "        self.sentence_transformer = SentenceTransformer(sentence_transformer_name)\n",
    "        self.embedded_sentences = self.sentence_transformer.encode(self.sentences)\n",
    "        self.random_seed = 42\n",
    "        \n",
    "        if true_labels is None:\n",
    "            self.true_labels = np.zeros(len(self.sentences))\n",
    "        self.eval_metrics_list=supervised_eval_metrics_list\n",
    "\n",
    "    # Evaluate metrics\n",
    "    def eval_metrics(self,actual, pred):\n",
    "    \n",
    "        results = defaultdict(None)\n",
    "        \n",
    "        for met in self.eval_metrics_list:\n",
    "            if met == 'silhouette_score':\n",
    "                results['silhouette_score']=silhouette_score(self.embedded_sentences,pred)\n",
    "            else:\n",
    "                results[met] = get_scorer(met)._score_func(actual,pred)\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def train(self):\n",
    "        # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        for current_n in range(self.cluster_min, self.cluster_max, self.cluster_step):\n",
    "            with mlflow.start_run():\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                mlflow.log_param(\"n_clusters\", current_n)\n",
    "\n",
    "                km = KMeans(n_clusters=current_n)\n",
    "\n",
    "                predicted_labels = km.fit_predict(self.embedded_sentences)\n",
    "                predicted_2d = km.transform(self.embedded_sentences)\n",
    "\n",
    "                metrics_dict = self.eval_metrics(self.true_labels,predicted_labels)\n",
    "\n",
    "                # Print out ElasticNet model metrics\n",
    "\n",
    "                print(f\"n_cluster={current_n}\")\n",
    "                for met in self.eval_metrics_list:\n",
    "                    print(f'{met} = {metrics_dict[met]:.4f}')\n",
    "                    mlflow.log_metric(met, metrics_dict[met])\n",
    "\n",
    "\n",
    "                mlflow.sklearn.log_model(km, f\"KMeans (n={current_n})\")\n",
    "               # mlflow.sklearn.save_model(km,'./my_models')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6e3945c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/ares/.cache/torch/sentence_transformers/emilyalsentzer_Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/ares/.cache/torch/sentence_transformers/emilyalsentzer_Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "SentClust = SentenceKmeans(sentences,supervised_eval_metrics_list=CLUSTER_EVAL_METRICS_LIST)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f40e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cluster=1\n",
      "adjusted_rand_score = 1.0000 \n",
      "\n",
      "adjusted_mutual_info_score = 1.0000 \n",
      "\n",
      "normalized_mutual_info_score = 1.0000 \n",
      "\n",
      "homogeneity_score = 1.0000 \n",
      "\n",
      "completeness_score = 1.0000 \n",
      "\n",
      "v_measure_score = 1.0000 \n",
      "\n",
      "n_cluster=2\n",
      "adjusted_rand_score = 0.0000 \n",
      "\n",
      "adjusted_mutual_info_score = 0.0000 \n",
      "\n",
      "normalized_mutual_info_score = 0.0000 \n",
      "\n",
      "homogeneity_score = 1.0000 \n",
      "\n",
      "completeness_score = 0.0000 \n",
      "\n",
      "v_measure_score = 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SentClust.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_1",
   "language": "python",
   "name": "kaggle_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
