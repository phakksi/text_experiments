{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "131c7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logging import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import cloudpickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a378c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# CLUSTER\n",
    "CLUSTER_MIN = 2\n",
    "CLUSTER_MAX = 15\n",
    "CLUSTER_STEP = 1\n",
    "\n",
    "LOG_ONLY_BEST=True\n",
    "\n",
    "# data\n",
    "DATA_PATH = './data/yelp_labelled.txt'\n",
    "\n",
    "# sentence transformer\n",
    "# choose one from https://www.sbert.net/docs/pretrained_models.html\n",
    "MODEL_NAME = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "\n",
    "# Eval Metrics\n",
    "EVAL_METRICS = ['silhouette_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b1883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file {DATA_PATH}...\n",
      "Load complete: 1000 rows and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "logger.info('Loading file {DATA_PATH}...')\n",
    "df = pd.read_csv(DATA_PATH, header=None,\n",
    "                 sep='\\t', names=['sentence', 'label'])\n",
    "logger.info(f'Load complete: {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f25b04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sentence transformer multi-qa-MiniLM-L6-cos-v1...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sentcluster import BertEmbedder\n",
    "logger.info(f'Loading sentence transformer {MODEL_NAME}...')\n",
    "embedder = BertEmbedder(MODEL_NAME)\n",
    "logger.info(f'done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cff64b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.48it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.83it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 77.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04648494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.set_params(**{'clusterer__n_clusters':4})\n",
    "predicted_2d = pipe.fit(df.sentence)\n",
    "predicted_labels = pipe.predict(df.sentence)\n",
    "\n",
    "sil_score = silhouette_score(pipe['embedder'].transform(df.sentence),predicted_labels)\n",
    "print(sil_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2a8f706",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d03ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import version_info\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(\n",
    "    major=version_info.major, minor=version_info.minor, micro=version_info.micro\n",
    ")\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\"],\n",
    "    \"dependencies\": [\"python={}\".format(PYTHON_VERSION), \"pip\"],\n",
    "    \"pip\": [\n",
    "        \"mlflow\",\n",
    "        \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "        \"vaderSentiment==3.3.2\",\n",
    "    ],\n",
    "    \"name\": \"mlflow-env\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be44afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.78it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 75.08it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.76it/s]\n",
      "n_cluster=2, silhouette_score=0.06888\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.95it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 65.15it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.37it/s]\n",
      "n_cluster=3, silhouette_score=0.05623\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 67.76it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.01it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 69.07it/s]\n",
      "n_cluster=4, silhouette_score=0.04648\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.14it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 76.65it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 72.74it/s]\n",
      "n_cluster=5, silhouette_score=0.04916\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.71it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.28it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 71.60it/s]\n",
      "n_cluster=6, silhouette_score=0.04911\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 59.85it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.07it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 70.52it/s]\n",
      "n_cluster=7, silhouette_score=0.04741\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.91it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.58it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.85it/s]\n",
      "n_cluster=8, silhouette_score=0.04531\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 74.92it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 73.17it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 64.51it/s]\n",
      "n_cluster=9, silhouette_score=0.04295\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable, List\n",
    "#from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score,homogeneity_score,completeness_score,v_measure_score,silhouette_score\n",
    "from collections import namedtuple\n",
    "import importlib \n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import get_scorer,silhouette_score\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "pipe = Pipeline([('embedder',embedder),('clusterer',KMeans())])\n",
    "\n",
    "best_metric = np.Inf\n",
    "for current_n in range(CLUSTER_MIN, CLUSTER_MAX, CLUSTER_STEP):\n",
    "    with mlflow.start_run():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        mlflow.log_param(\"n_clusters\", current_n)\n",
    "        model_start_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        pipe.set_params(**{'clusterer__n_clusters':current_n})\n",
    "        predicted_2d = pipe.fit(df.sentence)\n",
    "        predicted_labels = pipe.predict(df.sentence)\n",
    "\n",
    "        current_metric = silhouette_score(pipe['embedder'].transform(df.sentence),predicted_labels)\n",
    "        \n",
    "        # Print out Silhouette Score and log it in mlflow\n",
    "        logger.info(f\"n_cluster={current_n}, silhouette_score={current_metric:.5f}\")\n",
    "\n",
    "        if LOG_ONLY_BEST:\n",
    "            if current_metric < best_metric:\n",
    "                best_metric = current_metric \n",
    "                mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "                mlflow.log_metric('silhouette_score', best_metric)\n",
    "                mlflow.sklearn.save_model(pipe,f'models/{model_start_time}_{MODEL_NAME}_KMeans_(n={current_n}',conda_env=conda_env)\n",
    "        else:\n",
    "                mlflow.sklearn.log_model(pipe, f\"{MODEL_NAME}_KMeans_(n={current_n})\",conda_env=conda_env)\n",
    "                mlflow.log_metric('silhouette_score', current_metric)\n",
    "                mlflow.sklearn.save_model(pipe,f'models/{model_start_time}_{MODEL_NAME}_KMeans_(n={current_n}',conda_env=conda_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_1",
   "language": "python",
   "name": "kaggle_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
